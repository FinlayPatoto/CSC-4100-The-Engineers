         		+--------------------+
			|      CSC 4100      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

John Donnell <jmdonnell43@tntech.edu>
Finlay Patoto <	frpatoto42@tntech.edu>
Katie Swinea <keswinea42@tntech.edu>

---- PRELIMINARIES ----

This is the final submission for the design document. It covers all the
implementations for all the tests including the advanced scheduler. We
not the use of generative AI, which is allowed by the instructer as long
as we did our own work and only used it for explanation and helping with
small parts, like specific functions, of the project.

The documentation was used extensively to determine the implementation.
Chatgpt was also used to help debug, for example helping find he misuse
of two similarly named variables. It was also used to help interperate
expectations of the document.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct list waiting_queue;

This struct decleration was used to implement the queue storing the sleeping
threads. It is declared as a global list in the timer.c file.

bool compare_wakeups(struct list_elem* first, struct list_elem* second)

This function was added to order the waiting queue. It's used for inserting 
threads into the queue to determine its placement.

struct thread
  {
    /* Owned by thread.c. */
    tid_t tid;                          /* Thread identifier. */
    enum thread_status status;          /* Thread state. */
    char name[16];                      /* Name (for debugging purposes). */
    uint8_t *stack;                     /* Saved stack pointer. */
    int priority;                       /* Priority. */
    struct list_elem allelem;           /* List element for all threads list. */

    /* Shared between thread.c and synch.c. */
    struct list_elem elem;              /* List element. */

    int64_t wakeup; // Used for sleep without busy wait

#ifdef USERPROG
    /* Owned by userprog/process.c. */
    uint32_t *pagedir;                  /* Page directory. */
#endif

    /* Owned by thread.c. */
    unsigned magic;                     /* Detects stack overflow. */
  };

The wakeup variable was added to thread struct. It determines when
the thread will wake up and helps with the ordering of the waiting queue.

enum intr_level current_level = intr_disable(); 

This was implemented in the timer_sleep() function for breifly disabling the
interrupts. It is used very similarly to the implementation in thread yield.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

The function timer_sleep() still checks the interrupt level and starts 
the timer_ticks, but it then goes on to use the enum for the interrupt 
levels and store the wake up time in the thread structure. It then 
blocks the thread. During this time, the interrupts are disabled to
these changes can be made quickly and atomically. The interrupt handler 
will use the waiting queue to check if any threads need to be woken up.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The interrupt handler takes the first thread in the waiting queue and checks 
if it is its wake up time. It removes the thread from the list and unblocks 
it at the threads wake up time. Otherwise, it will exit the handler. Other
strategies were implemented like using an if statement to break out of 
the function also doesn't waste time if it is not ready to be removed. 
Since the waiting queue is also ordered, it only has to consider one element.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

This is done by turning off the interrupts breifly to modify shared
variables like the waiting queue itself. Once the thread is added and
blocked, interrupts are turned back on.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

We will be turning off the interrupts, which guarantees that the timer
interrupt will not preempt the thread while modifying the variables
to ensure correct values for the thread being added to the waiting
queue.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this initial design because it avoids busy waiting and should 
improve efficiency. The queue enables us to have necessary work done each
tick and allows the timer interrupt to run quickly and safely. The disabling of
interrupts was also modeled after the thread yield function which was originally
used in the busy waiting while loop. This helped us ensure this use was appropriate.
Finally, we used a sorted list to order the wake ups rather than searching for the 
first, or current, wake up time which is more efficient and might keep timers from
missing a wake up.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
    /* Owned by thread.c. */
    tid_t tid;                          /* Thread identifier. */
    enum thread_status status;          /* Thread state. */
    char name[16];                      /* Name (for debugging purposes). */
    uint8_t *stack;                     /* Saved stack pointer. */
    int base_priority;
    int priority;                       /* Priority. */
    struct list_elem allelem;           /* List element for all threads list. */

    struct list_elem elem;              

    int64_t wakeup; // Used for sleep without busy wait

    struct list donations; // Tracks threads that have donated priotiry
    struct list_elem donation_elem; 
    struct lock *waiting_on_lock; 

#ifdef USERPROG
    /* Owned by userprog/process.c. */
    uint32_t *pagedir;                  /* Page directory. */
#endif

    /* Owned by thread.c. */
    unsigned magic;                     /* Detects stack overflow. */
  };

The thread struct was changed to include lists and locks to keep 
track of threads and locks for donations.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

A list was made to hold each donation that a thread recieved. A list for
elements was also made for similar purposes. This kept track of which thread
has the highest priority so it can have the lock next. If a thread donates 
and then this thread donates it will be a list pointing to another lock's list, 
because the thread stores the list and locks for donations as pointers to a 
struct. This particular structure can be seen in the diagram submitted as
a .png file.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

To ensure that the highest-priority thread is woken up first, we inserted 
the threads in order. This was done with the list_insert_ordered and simple
compare functions for the priority, semaphores, and wake up times.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

This will happen when the lock that is trying to be acquired already has
a holder. The donate function is called to temporarily switch the priorites 
between the two threads. It will do this multiple times if needed. The lock 
will be donated even if it is nested because lock_acquire will be called when 
the new thread tries to get the lock.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

A list of elements is made from all the donations the thread holding the lock has. 
It goes through the list and sees if the donor is waiting on the lock being 
released. If it is, that list is removed since this lock is no longer held by the 
thread. The thread's priority will then be set back to normal. The lock will be 
aquired by the highest priority thread through the list which is ordered.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A race condition in thread_set_priority() could occur if a thread updates its 
priority while priority donation is happening, leading to an error. One possible 
approach would disable interrupts during priority updating. If a thread lowers 
its priority, it flags the CPU if a higher-priority thread is ready. You shouldn't 
use a lock because it could lead to potential overlap and race conditions with other
lock logic, so time interrupt disabling is the best possible option. 


---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because it should effectively handle priority inversion with 
the ability to have dynamic priority donation. Using an ordered waiters list helps 
keep the implementation on the simple side and ensures correct thread scheduling, 
and recursive donation supports nested locks. We also tried to intentionally design
everything to be efficent including putting extranous functions like sorting and yields 
outside of sections disabling interrupts.

			  ADVANCED SCHEDULER (Extra Credit)
			  =================================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

bool thread_mlfqs;
This variable was added to indicate if mlfqs is on or off. External also defined
in header.

int load_avg = 0;
This vairable was added and intialized for the system wide load average. External
also defined in header.

int recent_cpu;
Variable for recent cpu to be stored for thread.

int nice;
Variable for nice value to be stored for thread.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu           priority             thread
ticks     A   B   C      A     B     C       to run
-----   ---- ---- ----  ----  ----  ----    -------
   0      0    0    0    63    61    59      A  
   4      4    0    0    62    61    59      A  
   8      8    0    0    61    61    59      A
  12     12    0    0    60    61    59      B  
  16     12    4    0    60    60    59      A  
  20     16    4    0    59    60    59      B  
  24     16    8    0    59    59    59      A
  28     20    8    0    58    59    59      B  
  32     20   12    4    58    58    59      C  
  36     20   12    8    58    58    58      A

Note ties, like when timer ticks is 8, were broken alphabetically.

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

As noted above, ties were broken alpahbetically because we assumed those 
went in first. If a tie happens it is implemented as a first in first out
queue.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Most of the calculations using fixed point arithmetic is inside interrupt 
context making context switching easier but puts more pressure on the 
interrupt handler if the calculations are significant and large.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

As mentioned above, there is a lot of fixed point arithmetic being done in
the interrupt. This helps with context switching but has the interrupts doing 
a lot. Using fixed point macros make the code readable and increase usability.
However, ties are broken based on FIFO which under certain conditions, might
starve certain threads. If given more time, we would try to implement a round
robin approach since it would be the most fair one.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We used abstract data because the equations for fixed point arithmetic were
reused a lot. The equations also had to be used together for equations that
multiple by a fraction and then add two multiplied results. That is a lot of
equations being used and was much simpler to implement this way. In fact, we 
originally tried to use the equations without in abstract data, but quickly
found it was too much to keep track of.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

We honestly feel like all of the assignments were the right amount of difficulty.
While Alarm might have been easier and Advnaced Scheduling harder compared to each
other and the Priority, the combination of all three balanced each other out. If
the difficulty was changed, the project could become much higher or lower depending
on the changes.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

The Prioirty part of the assingment was very insightful. 

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

Again, we think the project's difficulty is just right. The information given in
class was very helpful and any issues could be addressed in office hours.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

We never went to the TA. Most questions we had were small and implementation
specific.

>> Any other comments?

No other comments at this time.
